{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec6ad32",
   "metadata": {},
   "source": [
    "# Importing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "617cf56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82365e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row Labels</th>\n",
       "      <th>Count of Property Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apartment</td>\n",
       "      <td>5698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bed &amp; Breakfast</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boat</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boutique hotel</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Row Labels  Count of Property Type\n",
       "0        Apartment                  5698.0\n",
       "1  Bed & Breakfast                   178.0\n",
       "2             Boat                     2.0\n",
       "3   Boutique hotel                     3.0\n",
       "4            Cabin                     7.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataA = pd.read_csv('belgium.csv')\n",
    "dataA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349f2651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c99b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Row Labels', 'Count of Property Type'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e24e96e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Price', 'Room Type', 'Property Type', 'Bedrooms',\\n       'Host Total Listings Count'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdataA\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRoom Type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProperty Type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBedrooms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHost Total Listings Count\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m data\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Price', 'Room Type', 'Property Type', 'Bedrooms',\\n       'Host Total Listings Count'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "data = dataA[['Price','Room Type','Property Type','Bedrooms','Host Total Listings Count']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7529b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price']=data['Price'].fillna(data['Price'].mean())\n",
    "data['Host Total Listings Count']=data['Host Total Listings Count'].fillna(data['Host Total Listings Count'].mean())\n",
    "data['Bedrooms']=data['Bedrooms'].fillna(data['Bedrooms'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b82814",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[(data['Property Type'] == 'Apartment') | (data['Property Type'] == 'House') | (data['Property Type'] == 'Loft') | (data['Property Type'] == 'Bed & Breakfast')]\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "data['Room Type']=le.fit_transform(data['Room Type'])\n",
    "data['Property Type']=le.fit_transform(data['Property Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47860fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bedrooms_mean = data['Bedrooms'].mean()\n",
    "print(Bedrooms_mean)\n",
    "data[\"Bedrooms\"].fillna(Bedrooms_mean, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a84924",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79387cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns = ['Property Type'])\n",
    "y = data['Property Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2117e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e1da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "print(X.shape, y.shape)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b639b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_x_train = scaler.fit_transform(X_train)\n",
    "scaled_x_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9d3044",
   "metadata": {},
   "source": [
    "# KNN classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb4d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae222ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors = 4)\n",
    "knn_model.fit(scaled_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c630834",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_model.predict(scaled_x_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "accuracy_score(y_test,y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792f3c52",
   "metadata": {},
   "source": [
    "# Elbow method for chossing the value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d62a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "test_error_rates = []\n",
    "for k in range(1,30):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn_model.fit(scaled_x_train,y_train)\n",
    "    y_pred_test = knn_model.predict(scaled_x_test)\n",
    "    test_error = 1 - accuracy_score(y_test,y_pred_test)\n",
    "    test_error_rates.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafdc70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39f6588",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(8,7),dpi = 200)\n",
    "plt.plot(range(1,30) , test_error_rates, label = 'Test_error')\n",
    "plt.legend()\n",
    "plt.xlabel('k.value')\n",
    "plt.ylabel('error rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590a7ac4",
   "metadata": {},
   "source": [
    "From the above graph we can say optimal value for k is 6 because the graph of error rate increases after that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed79b9f4",
   "metadata": {},
   "source": [
    "# Full cross validation grid search for k values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d9db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "knn = KNeighborsClassifier()\n",
    "knn.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568318d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "operation = [('scaler',scaler),('knn',knn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d926c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline(operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c2d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c361c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = list(range(1,20))\n",
    "k_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d45151",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'knn__n_neighbors': k_values}\n",
    "full_cv_classifier = GridSearchCV(pipe,param_grid,cv = 11, scoring = 'accuracy' )\n",
    "full_cv_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1dd749",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cv_classifier.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c207db",
   "metadata": {},
   "source": [
    "# Optimal value for k is 6 from the above method so we can bulid the model according to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e70333",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "knn10 = KNeighborsClassifier(n_neighbors = 10)\n",
    "operation = [('scaler',scaler),('knn10',knn10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649041ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(operation)\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = knn10.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e4a72f",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5158ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba50531",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_test,y_pred_knn)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d424fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "acc = sklearn.metrics.accuracy_score(y_test, y_pred_knn)\n",
    "prec = round(sklearn.metrics.precision_score(y_test, y_pred_knn ,average= 'micro'),2)\n",
    "rec = round(sklearn.metrics.recall_score(y_test, y_pred_knn ,average= 'micro'),2)\n",
    "f1 = round(sklearn.metrics.f1_score(y_test, y_pred_knn,average='micro'),2)\n",
    "print('accuracy =',acc, ' precision =', prec, ' recall =', rec, ' f1 =',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bb97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Actual':y_test,'Predicted':y_pred_knn})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087101c2",
   "metadata": {},
   "source": [
    "# Naive_bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980eae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2dff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_NB = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64b01c1",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763fbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45841ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred_NB)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305eff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "acc = sklearn.metrics.accuracy_score(y_test, y_pred_NB)\n",
    "prec = round(sklearn.metrics.precision_score(y_test, y_pred_NB ,average= 'micro'),2)\n",
    "rec = round(sklearn.metrics.recall_score(y_test, y_pred_NB ,average= 'micro'),2)\n",
    "f1 = round(sklearn.metrics.f1_score(y_test, y_pred_NB,average='micro'),2)\n",
    "print('accuracy =',acc, ' precision =', prec, ' recall =', rec, ' f1 =',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920651d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Actual':y_test,'Predicted':y_pred_NB})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823cdf08",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33801ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55387e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_l = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a5b994",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f98b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_l)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf55589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "acc = sklearn.metrics.accuracy_score(y_test, y_pred_l)\n",
    "prec = round(sklearn.metrics.precision_score(y_test, y_pred_l ,average= 'micro'),2)\n",
    "rec = round(sklearn.metrics.recall_score(y_test, y_pred_l ,average= 'micro'),2)\n",
    "f1 = round(sklearn.metrics.f1_score(y_test, y_pred_l,average='micro'),2)\n",
    "print('accuracy =',acc, ' precision =', prec, ' recall =', rec, ' f1 =',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd54b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Actual':y_test,'Predicted':y_pred_l})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f8c01c",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d745049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d41348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)      \n",
    "rf = rf.fit(X_train,y_train)\n",
    "y_pred_RF=rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce306df",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9dd157",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77acde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_RF)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f047741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "acc = sklearn.metrics.accuracy_score(y_test, y_pred_RF)\n",
    "prec = round(sklearn.metrics.precision_score(y_test, y_pred_RF ,average= 'micro'),2)\n",
    "rec = round(sklearn.metrics.recall_score(y_test, y_pred_RF ,average= 'micro'),2)\n",
    "f1 = round(sklearn.metrics.f1_score(y_test, y_pred_RF,average='micro'),2)\n",
    "print('accuracy =',acc, ' precision =', prec, ' recall =', rec, ' f1 =',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907883f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Actual':y_test,'Predicted':y_pred_RF})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d99e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame({'Actual':y_test,'Predicted_Knn':y_pred_knn,'Predicted_logistic':y_pred_l,'Predicted_NB':y_pred_NB,'Predicted_RF':y_pred_RF})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3943823c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6066420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
